{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "Neural Networks",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pratikwatwani/Applied-Data-Science/blob/master/Session%2011/Neural%20Networks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i5UVFoAmkzhH",
        "colab_type": "text"
      },
      "source": [
        "# Homework 7_Session 11. Neural networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OT9XSvkFkzhJ",
        "colab_type": "text"
      },
      "source": [
        "The purpose of the below is to classify days over years 2017-2018 by their corresponding mobility patterns between 10 zones in Taipei (quantified by an aggregated temporal network of subway ridership flows across the city)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dtm0HTHDkzhK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#use Python 3.7\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Input, Dense\n",
        "from keras.utils import np_utils"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FW2LITZVkzhN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#read the data\n",
        "TNet=pd.read_csv('https://raw.githubusercontent.com/pratikwatwani/Applied-Data-Science/master/data/taipeiD_TNet2.csv',header=None);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ox85yef9kzhP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "outputId": "9985a37a-cec1-43b3-b058-43a317d54dfd"
      },
      "source": [
        "TNet.head() \n",
        "#each row represents a 10x10 adjacency matrix of the normalized Taipei subway mobility network between 10 zones flattened into a 100x1 row corresponding to a single day\n",
        "#days start at jan-1-2017"
      ],
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>60</th>\n",
              "      <th>61</th>\n",
              "      <th>62</th>\n",
              "      <th>63</th>\n",
              "      <th>64</th>\n",
              "      <th>65</th>\n",
              "      <th>66</th>\n",
              "      <th>67</th>\n",
              "      <th>68</th>\n",
              "      <th>69</th>\n",
              "      <th>70</th>\n",
              "      <th>71</th>\n",
              "      <th>72</th>\n",
              "      <th>73</th>\n",
              "      <th>74</th>\n",
              "      <th>75</th>\n",
              "      <th>76</th>\n",
              "      <th>77</th>\n",
              "      <th>78</th>\n",
              "      <th>79</th>\n",
              "      <th>80</th>\n",
              "      <th>81</th>\n",
              "      <th>82</th>\n",
              "      <th>83</th>\n",
              "      <th>84</th>\n",
              "      <th>85</th>\n",
              "      <th>86</th>\n",
              "      <th>87</th>\n",
              "      <th>88</th>\n",
              "      <th>89</th>\n",
              "      <th>90</th>\n",
              "      <th>91</th>\n",
              "      <th>92</th>\n",
              "      <th>93</th>\n",
              "      <th>94</th>\n",
              "      <th>95</th>\n",
              "      <th>96</th>\n",
              "      <th>97</th>\n",
              "      <th>98</th>\n",
              "      <th>99</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.017943</td>\n",
              "      <td>0.005415</td>\n",
              "      <td>0.003590</td>\n",
              "      <td>0.008316</td>\n",
              "      <td>0.007859</td>\n",
              "      <td>0.012942</td>\n",
              "      <td>0.012196</td>\n",
              "      <td>0.019543</td>\n",
              "      <td>0.001196</td>\n",
              "      <td>0.003327</td>\n",
              "      <td>0.004588</td>\n",
              "      <td>0.016362</td>\n",
              "      <td>0.003059</td>\n",
              "      <td>0.006420</td>\n",
              "      <td>0.009864</td>\n",
              "      <td>0.005530</td>\n",
              "      <td>0.007357</td>\n",
              "      <td>0.017389</td>\n",
              "      <td>0.000923</td>\n",
              "      <td>0.001672</td>\n",
              "      <td>0.002640</td>\n",
              "      <td>0.002878</td>\n",
              "      <td>0.003133</td>\n",
              "      <td>0.001715</td>\n",
              "      <td>0.003610</td>\n",
              "      <td>0.001157</td>\n",
              "      <td>0.002406</td>\n",
              "      <td>0.004315</td>\n",
              "      <td>0.000550</td>\n",
              "      <td>0.001456</td>\n",
              "      <td>0.008631</td>\n",
              "      <td>0.007123</td>\n",
              "      <td>0.002301</td>\n",
              "      <td>0.010586</td>\n",
              "      <td>0.007468</td>\n",
              "      <td>0.010193</td>\n",
              "      <td>0.010568</td>\n",
              "      <td>0.020925</td>\n",
              "      <td>0.001346</td>\n",
              "      <td>0.002716</td>\n",
              "      <td>...</td>\n",
              "      <td>0.010876</td>\n",
              "      <td>0.007325</td>\n",
              "      <td>0.002859</td>\n",
              "      <td>0.009160</td>\n",
              "      <td>0.013417</td>\n",
              "      <td>0.009071</td>\n",
              "      <td>0.050107</td>\n",
              "      <td>0.043340</td>\n",
              "      <td>0.000679</td>\n",
              "      <td>0.003823</td>\n",
              "      <td>0.013696</td>\n",
              "      <td>0.014299</td>\n",
              "      <td>0.005237</td>\n",
              "      <td>0.015900</td>\n",
              "      <td>0.025870</td>\n",
              "      <td>0.021652</td>\n",
              "      <td>0.035190</td>\n",
              "      <td>0.049923</td>\n",
              "      <td>0.002971</td>\n",
              "      <td>0.009171</td>\n",
              "      <td>0.001081</td>\n",
              "      <td>0.001064</td>\n",
              "      <td>0.000710</td>\n",
              "      <td>0.001091</td>\n",
              "      <td>0.003131</td>\n",
              "      <td>0.008141</td>\n",
              "      <td>0.000839</td>\n",
              "      <td>0.004099</td>\n",
              "      <td>0.009125</td>\n",
              "      <td>0.005163</td>\n",
              "      <td>0.002529</td>\n",
              "      <td>0.001533</td>\n",
              "      <td>0.001860</td>\n",
              "      <td>0.002375</td>\n",
              "      <td>0.005408</td>\n",
              "      <td>0.008922</td>\n",
              "      <td>0.003945</td>\n",
              "      <td>0.011075</td>\n",
              "      <td>0.005073</td>\n",
              "      <td>0.012708</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.021283</td>\n",
              "      <td>0.005215</td>\n",
              "      <td>0.003530</td>\n",
              "      <td>0.009359</td>\n",
              "      <td>0.007803</td>\n",
              "      <td>0.014288</td>\n",
              "      <td>0.011185</td>\n",
              "      <td>0.019044</td>\n",
              "      <td>0.001382</td>\n",
              "      <td>0.003499</td>\n",
              "      <td>0.004859</td>\n",
              "      <td>0.016886</td>\n",
              "      <td>0.003053</td>\n",
              "      <td>0.007339</td>\n",
              "      <td>0.009820</td>\n",
              "      <td>0.005745</td>\n",
              "      <td>0.006608</td>\n",
              "      <td>0.016490</td>\n",
              "      <td>0.001023</td>\n",
              "      <td>0.001866</td>\n",
              "      <td>0.002897</td>\n",
              "      <td>0.002929</td>\n",
              "      <td>0.002973</td>\n",
              "      <td>0.001817</td>\n",
              "      <td>0.003471</td>\n",
              "      <td>0.001210</td>\n",
              "      <td>0.002197</td>\n",
              "      <td>0.004039</td>\n",
              "      <td>0.000664</td>\n",
              "      <td>0.001655</td>\n",
              "      <td>0.009672</td>\n",
              "      <td>0.007348</td>\n",
              "      <td>0.002248</td>\n",
              "      <td>0.012551</td>\n",
              "      <td>0.007475</td>\n",
              "      <td>0.011087</td>\n",
              "      <td>0.009090</td>\n",
              "      <td>0.020644</td>\n",
              "      <td>0.001560</td>\n",
              "      <td>0.003032</td>\n",
              "      <td>...</td>\n",
              "      <td>0.010139</td>\n",
              "      <td>0.006609</td>\n",
              "      <td>0.002760</td>\n",
              "      <td>0.008469</td>\n",
              "      <td>0.010956</td>\n",
              "      <td>0.009114</td>\n",
              "      <td>0.046897</td>\n",
              "      <td>0.038464</td>\n",
              "      <td>0.000647</td>\n",
              "      <td>0.003762</td>\n",
              "      <td>0.014380</td>\n",
              "      <td>0.016011</td>\n",
              "      <td>0.003765</td>\n",
              "      <td>0.017911</td>\n",
              "      <td>0.022929</td>\n",
              "      <td>0.021901</td>\n",
              "      <td>0.034270</td>\n",
              "      <td>0.040281</td>\n",
              "      <td>0.003776</td>\n",
              "      <td>0.009128</td>\n",
              "      <td>0.001298</td>\n",
              "      <td>0.001179</td>\n",
              "      <td>0.000663</td>\n",
              "      <td>0.001337</td>\n",
              "      <td>0.003490</td>\n",
              "      <td>0.008978</td>\n",
              "      <td>0.000753</td>\n",
              "      <td>0.004377</td>\n",
              "      <td>0.010360</td>\n",
              "      <td>0.005964</td>\n",
              "      <td>0.002803</td>\n",
              "      <td>0.001757</td>\n",
              "      <td>0.001783</td>\n",
              "      <td>0.002549</td>\n",
              "      <td>0.005515</td>\n",
              "      <td>0.009650</td>\n",
              "      <td>0.003596</td>\n",
              "      <td>0.009618</td>\n",
              "      <td>0.005946</td>\n",
              "      <td>0.013709</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.028988</td>\n",
              "      <td>0.006511</td>\n",
              "      <td>0.005591</td>\n",
              "      <td>0.012970</td>\n",
              "      <td>0.007816</td>\n",
              "      <td>0.015878</td>\n",
              "      <td>0.010973</td>\n",
              "      <td>0.015768</td>\n",
              "      <td>0.002252</td>\n",
              "      <td>0.005388</td>\n",
              "      <td>0.006879</td>\n",
              "      <td>0.013790</td>\n",
              "      <td>0.003706</td>\n",
              "      <td>0.009401</td>\n",
              "      <td>0.008878</td>\n",
              "      <td>0.006245</td>\n",
              "      <td>0.006937</td>\n",
              "      <td>0.013613</td>\n",
              "      <td>0.001545</td>\n",
              "      <td>0.002790</td>\n",
              "      <td>0.005575</td>\n",
              "      <td>0.003375</td>\n",
              "      <td>0.004373</td>\n",
              "      <td>0.003305</td>\n",
              "      <td>0.005246</td>\n",
              "      <td>0.001148</td>\n",
              "      <td>0.002829</td>\n",
              "      <td>0.003980</td>\n",
              "      <td>0.000803</td>\n",
              "      <td>0.002643</td>\n",
              "      <td>0.013623</td>\n",
              "      <td>0.008729</td>\n",
              "      <td>0.003722</td>\n",
              "      <td>0.015259</td>\n",
              "      <td>0.006972</td>\n",
              "      <td>0.012822</td>\n",
              "      <td>0.009648</td>\n",
              "      <td>0.017857</td>\n",
              "      <td>0.002672</td>\n",
              "      <td>0.004533</td>\n",
              "      <td>...</td>\n",
              "      <td>0.011613</td>\n",
              "      <td>0.007232</td>\n",
              "      <td>0.003313</td>\n",
              "      <td>0.009770</td>\n",
              "      <td>0.008924</td>\n",
              "      <td>0.009524</td>\n",
              "      <td>0.039863</td>\n",
              "      <td>0.029368</td>\n",
              "      <td>0.000581</td>\n",
              "      <td>0.005011</td>\n",
              "      <td>0.013882</td>\n",
              "      <td>0.013373</td>\n",
              "      <td>0.003620</td>\n",
              "      <td>0.017100</td>\n",
              "      <td>0.018839</td>\n",
              "      <td>0.018666</td>\n",
              "      <td>0.026413</td>\n",
              "      <td>0.030177</td>\n",
              "      <td>0.003673</td>\n",
              "      <td>0.008805</td>\n",
              "      <td>0.002030</td>\n",
              "      <td>0.001531</td>\n",
              "      <td>0.000786</td>\n",
              "      <td>0.002192</td>\n",
              "      <td>0.004388</td>\n",
              "      <td>0.010398</td>\n",
              "      <td>0.000546</td>\n",
              "      <td>0.004129</td>\n",
              "      <td>0.011692</td>\n",
              "      <td>0.009807</td>\n",
              "      <td>0.004649</td>\n",
              "      <td>0.002555</td>\n",
              "      <td>0.002672</td>\n",
              "      <td>0.004291</td>\n",
              "      <td>0.007385</td>\n",
              "      <td>0.009558</td>\n",
              "      <td>0.004293</td>\n",
              "      <td>0.008791</td>\n",
              "      <td>0.010040</td>\n",
              "      <td>0.016301</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.029534</td>\n",
              "      <td>0.006471</td>\n",
              "      <td>0.005615</td>\n",
              "      <td>0.013017</td>\n",
              "      <td>0.007717</td>\n",
              "      <td>0.016098</td>\n",
              "      <td>0.011182</td>\n",
              "      <td>0.015815</td>\n",
              "      <td>0.002325</td>\n",
              "      <td>0.005443</td>\n",
              "      <td>0.006955</td>\n",
              "      <td>0.014044</td>\n",
              "      <td>0.003699</td>\n",
              "      <td>0.009330</td>\n",
              "      <td>0.008967</td>\n",
              "      <td>0.006290</td>\n",
              "      <td>0.007313</td>\n",
              "      <td>0.013566</td>\n",
              "      <td>0.001511</td>\n",
              "      <td>0.002833</td>\n",
              "      <td>0.005504</td>\n",
              "      <td>0.003456</td>\n",
              "      <td>0.004210</td>\n",
              "      <td>0.003239</td>\n",
              "      <td>0.005267</td>\n",
              "      <td>0.001098</td>\n",
              "      <td>0.002910</td>\n",
              "      <td>0.003914</td>\n",
              "      <td>0.000742</td>\n",
              "      <td>0.002519</td>\n",
              "      <td>0.013751</td>\n",
              "      <td>0.008552</td>\n",
              "      <td>0.003736</td>\n",
              "      <td>0.014924</td>\n",
              "      <td>0.006757</td>\n",
              "      <td>0.012755</td>\n",
              "      <td>0.009960</td>\n",
              "      <td>0.017484</td>\n",
              "      <td>0.002665</td>\n",
              "      <td>0.004498</td>\n",
              "      <td>...</td>\n",
              "      <td>0.011870</td>\n",
              "      <td>0.007473</td>\n",
              "      <td>0.003513</td>\n",
              "      <td>0.010152</td>\n",
              "      <td>0.009209</td>\n",
              "      <td>0.009930</td>\n",
              "      <td>0.041379</td>\n",
              "      <td>0.029797</td>\n",
              "      <td>0.000618</td>\n",
              "      <td>0.005187</td>\n",
              "      <td>0.013526</td>\n",
              "      <td>0.012225</td>\n",
              "      <td>0.003561</td>\n",
              "      <td>0.016417</td>\n",
              "      <td>0.018527</td>\n",
              "      <td>0.017725</td>\n",
              "      <td>0.025343</td>\n",
              "      <td>0.030699</td>\n",
              "      <td>0.003375</td>\n",
              "      <td>0.007993</td>\n",
              "      <td>0.002014</td>\n",
              "      <td>0.001469</td>\n",
              "      <td>0.000773</td>\n",
              "      <td>0.002228</td>\n",
              "      <td>0.004599</td>\n",
              "      <td>0.010936</td>\n",
              "      <td>0.000596</td>\n",
              "      <td>0.004077</td>\n",
              "      <td>0.012252</td>\n",
              "      <td>0.009988</td>\n",
              "      <td>0.004611</td>\n",
              "      <td>0.002473</td>\n",
              "      <td>0.002636</td>\n",
              "      <td>0.004195</td>\n",
              "      <td>0.007255</td>\n",
              "      <td>0.009487</td>\n",
              "      <td>0.004316</td>\n",
              "      <td>0.008729</td>\n",
              "      <td>0.010296</td>\n",
              "      <td>0.016437</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.029333</td>\n",
              "      <td>0.006525</td>\n",
              "      <td>0.005727</td>\n",
              "      <td>0.013098</td>\n",
              "      <td>0.007692</td>\n",
              "      <td>0.016358</td>\n",
              "      <td>0.011000</td>\n",
              "      <td>0.015677</td>\n",
              "      <td>0.002344</td>\n",
              "      <td>0.005527</td>\n",
              "      <td>0.006860</td>\n",
              "      <td>0.013586</td>\n",
              "      <td>0.003710</td>\n",
              "      <td>0.009243</td>\n",
              "      <td>0.008994</td>\n",
              "      <td>0.006580</td>\n",
              "      <td>0.007113</td>\n",
              "      <td>0.014127</td>\n",
              "      <td>0.001536</td>\n",
              "      <td>0.002922</td>\n",
              "      <td>0.005472</td>\n",
              "      <td>0.003366</td>\n",
              "      <td>0.004166</td>\n",
              "      <td>0.003233</td>\n",
              "      <td>0.005255</td>\n",
              "      <td>0.001152</td>\n",
              "      <td>0.002889</td>\n",
              "      <td>0.003851</td>\n",
              "      <td>0.000735</td>\n",
              "      <td>0.002525</td>\n",
              "      <td>0.013695</td>\n",
              "      <td>0.008369</td>\n",
              "      <td>0.003819</td>\n",
              "      <td>0.015103</td>\n",
              "      <td>0.006924</td>\n",
              "      <td>0.012921</td>\n",
              "      <td>0.009824</td>\n",
              "      <td>0.017778</td>\n",
              "      <td>0.002605</td>\n",
              "      <td>0.004648</td>\n",
              "      <td>...</td>\n",
              "      <td>0.011968</td>\n",
              "      <td>0.007428</td>\n",
              "      <td>0.003594</td>\n",
              "      <td>0.010037</td>\n",
              "      <td>0.009058</td>\n",
              "      <td>0.009952</td>\n",
              "      <td>0.040614</td>\n",
              "      <td>0.030371</td>\n",
              "      <td>0.000633</td>\n",
              "      <td>0.005188</td>\n",
              "      <td>0.013355</td>\n",
              "      <td>0.011994</td>\n",
              "      <td>0.003674</td>\n",
              "      <td>0.016204</td>\n",
              "      <td>0.018132</td>\n",
              "      <td>0.017880</td>\n",
              "      <td>0.025106</td>\n",
              "      <td>0.030883</td>\n",
              "      <td>0.003316</td>\n",
              "      <td>0.008219</td>\n",
              "      <td>0.002130</td>\n",
              "      <td>0.001476</td>\n",
              "      <td>0.000823</td>\n",
              "      <td>0.002186</td>\n",
              "      <td>0.004413</td>\n",
              "      <td>0.010712</td>\n",
              "      <td>0.000562</td>\n",
              "      <td>0.004160</td>\n",
              "      <td>0.011789</td>\n",
              "      <td>0.009981</td>\n",
              "      <td>0.004694</td>\n",
              "      <td>0.002515</td>\n",
              "      <td>0.002677</td>\n",
              "      <td>0.004222</td>\n",
              "      <td>0.007269</td>\n",
              "      <td>0.009921</td>\n",
              "      <td>0.004387</td>\n",
              "      <td>0.008923</td>\n",
              "      <td>0.010381</td>\n",
              "      <td>0.016914</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 100 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         0         1         2   ...        97        98        99\n",
              "0  0.017943  0.005415  0.003590  ...  0.011075  0.005073  0.012708\n",
              "1  0.021283  0.005215  0.003530  ...  0.009618  0.005946  0.013709\n",
              "2  0.028988  0.006511  0.005591  ...  0.008791  0.010040  0.016301\n",
              "3  0.029534  0.006471  0.005615  ...  0.008729  0.010296  0.016437\n",
              "4  0.029333  0.006525  0.005727  ...  0.008923  0.010381  0.016914\n",
              "\n",
              "[5 rows x 100 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VYIKxV9BkzhS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#convert to an array and scale the data\n",
        "X=np.array(TNet);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BHuKaNkHkzhU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X=MinMaxScaler(feature_range=(0, 1), copy=True).fit_transform(X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gu4LSECmkzhW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d90fd97e-ec57-4e14-8aa3-3b3c85074db9"
      },
      "source": [
        "X.shape"
      ],
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(669, 100)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ErlgDYPBkzhY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b5f7aea6-9612-4d70-a64d-67fcb530a90f"
      },
      "source": [
        "#define day of the week corresponding to each day of observation; 0-Sunday, 1-Monday,...,6-Saturday\n",
        "y=np.array(range(669))%7; y[:10]"
      ],
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 2, 3, 4, 5, 6, 0, 1, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 133
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ayvjP2wjkzha",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "876df39a-1660-433e-f270-fb36e57c4e39"
      },
      "source": [
        "yc=np_utils.to_categorical(y) #get categorical binary variables isSunday, isMonday,...\n",
        "yc[:5]"
      ],
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 1., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 1., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PSB4kHhYkzhc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_test=X[400:,:]; X_train=X[:400,:]; #split the data into training and test\n",
        "y_test=yc[400:,:]; y_train=yc[:400,:]\n",
        "dim = X_train.shape[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G8qkzBH1qqoW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "4cbc3842-2fa0-460d-9f9f-3ce7ee6f81c4"
      },
      "source": [
        "print(X_test.shape)\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(269, 100)\n",
            "(400, 100)\n",
            "(400, 7)\n",
            "(269, 7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hoVuc7aOkzhi",
        "colab_type": "text"
      },
      "source": [
        "## Task 1. Classify weekdays/weekends\n",
        "Label the rows with ones for weekends, zeros for weekdays.\n",
        "Train a neural network with 4 layers of 30,10,3 and 1 (output) neurons over the training sample against this label, evaluating its performance over the test sample. Report the acheived accuracy (categorical) over the test sample\n",
        "\n",
        "First three layers use relu activation function, last one - sigmoid.\n",
        "Use loss='binary_crossentropy', optimizer='adam', 100 epochs, batch_size=20. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m_rdDQtRnbDy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        },
        "outputId": "c0fd6349-d990-4a06-bb1c-823a1db2a5a1"
      },
      "source": [
        "y"
      ],
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 2, 3, 4, 5, 6, 0, 1, 2, 3, 4, 5, 6, 0, 1, 2, 3, 4, 5, 6, 0,\n",
              "       1, 2, 3, 4, 5, 6, 0, 1, 2, 3, 4, 5, 6, 0, 1, 2, 3, 4, 5, 6, 0, 1,\n",
              "       2, 3, 4, 5, 6, 0, 1, 2, 3, 4, 5, 6, 0, 1, 2, 3, 4, 5, 6, 0, 1, 2,\n",
              "       3, 4, 5, 6, 0, 1, 2, 3, 4, 5, 6, 0, 1, 2, 3, 4, 5, 6, 0, 1, 2, 3,\n",
              "       4, 5, 6, 0, 1, 2, 3, 4, 5, 6, 0, 1, 2, 3, 4, 5, 6, 0, 1, 2, 3, 4,\n",
              "       5, 6, 0, 1, 2, 3, 4, 5, 6, 0, 1, 2, 3, 4, 5, 6, 0, 1, 2, 3, 4, 5,\n",
              "       6, 0, 1, 2, 3, 4, 5, 6, 0, 1, 2, 3, 4, 5, 6, 0, 1, 2, 3, 4, 5, 6,\n",
              "       0, 1, 2, 3, 4, 5, 6, 0, 1, 2, 3, 4, 5, 6, 0, 1, 2, 3, 4, 5, 6, 0,\n",
              "       1, 2, 3, 4, 5, 6, 0, 1, 2, 3, 4, 5, 6, 0, 1, 2, 3, 4, 5, 6, 0, 1,\n",
              "       2, 3, 4, 5, 6, 0, 1, 2, 3, 4, 5, 6, 0, 1, 2, 3, 4, 5, 6, 0, 1, 2,\n",
              "       3, 4, 5, 6, 0, 1, 2, 3, 4, 5, 6, 0, 1, 2, 3, 4, 5, 6, 0, 1, 2, 3,\n",
              "       4, 5, 6, 0, 1, 2, 3, 4, 5, 6, 0, 1, 2, 3, 4, 5, 6, 0, 1, 2, 3, 4,\n",
              "       5, 6, 0, 1, 2, 3, 4, 5, 6, 0, 1, 2, 3, 4, 5, 6, 0, 1, 2, 3, 4, 5,\n",
              "       6, 0, 1, 2, 3, 4, 5, 6, 0, 1, 2, 3, 4, 5, 6, 0, 1, 2, 3, 4, 5, 6,\n",
              "       0, 1, 2, 3, 4, 5, 6, 0, 1, 2, 3, 4, 5, 6, 0, 1, 2, 3, 4, 5, 6, 0,\n",
              "       1, 2, 3, 4, 5, 6, 0, 1, 2, 3, 4, 5, 6, 0, 1, 2, 3, 4, 5, 6, 0, 1,\n",
              "       2, 3, 4, 5, 6, 0, 1, 2, 3, 4, 5, 6, 0, 1, 2, 3, 4, 5, 6, 0, 1, 2,\n",
              "       3, 4, 5, 6, 0, 1, 2, 3, 4, 5, 6, 0, 1, 2, 3, 4, 5, 6, 0, 1, 2, 3,\n",
              "       4, 5, 6, 0, 1, 2, 3, 4, 5, 6, 0, 1, 2, 3, 4, 5, 6, 0, 1, 2, 3, 4,\n",
              "       5, 6, 0, 1, 2, 3, 4, 5, 6, 0, 1, 2, 3, 4, 5, 6, 0, 1, 2, 3, 4, 5,\n",
              "       6, 0, 1, 2, 3, 4, 5, 6, 0, 1, 2, 3, 4, 5, 6, 0, 1, 2, 3, 4, 5, 6,\n",
              "       0, 1, 2, 3, 4, 5, 6, 0, 1, 2, 3, 4, 5, 6, 0, 1, 2, 3, 4, 5, 6, 0,\n",
              "       1, 2, 3, 4, 5, 6, 0, 1, 2, 3, 4, 5, 6, 0, 1, 2, 3, 4, 5, 6, 0, 1,\n",
              "       2, 3, 4, 5, 6, 0, 1, 2, 3, 4, 5, 6, 0, 1, 2, 3, 4, 5, 6, 0, 1, 2,\n",
              "       3, 4, 5, 6, 0, 1, 2, 3, 4, 5, 6, 0, 1, 2, 3, 4, 5, 6, 0, 1, 2, 3,\n",
              "       4, 5, 6, 0, 1, 2, 3, 4, 5, 6, 0, 1, 2, 3, 4, 5, 6, 0, 1, 2, 3, 4,\n",
              "       5, 6, 0, 1, 2, 3, 4, 5, 6, 0, 1, 2, 3, 4, 5, 6, 0, 1, 2, 3, 4, 5,\n",
              "       6, 0, 1, 2, 3, 4, 5, 6, 0, 1, 2, 3, 4, 5, 6, 0, 1, 2, 3, 4, 5, 6,\n",
              "       0, 1, 2, 3, 4, 5, 6, 0, 1, 2, 3, 4, 5, 6, 0, 1, 2, 3, 4, 5, 6, 0,\n",
              "       1, 2, 3, 4, 5, 6, 0, 1, 2, 3, 4, 5, 6, 0, 1, 2, 3, 4, 5, 6, 0, 1,\n",
              "       2, 3, 4, 5, 6, 0, 1, 2, 3])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 138
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iIzdBDqsk-9k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        },
        "outputId": "dd55ce2a-d23f-43c0-8bc0-a1171e098696"
      },
      "source": [
        "y_c = y\n",
        "for idx, item in enumerate(y_c):\n",
        "  if ((item == 0)| (item == 6)):\n",
        "    y_c[idx] = 1\n",
        "  else:\n",
        "    y_c[idx] = 0\n",
        "\n",
        "y_c"
      ],
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1,\n",
              "       0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0,\n",
              "       0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0,\n",
              "       0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0,\n",
              "       0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0,\n",
              "       0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0,\n",
              "       1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1,\n",
              "       1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1,\n",
              "       0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0,\n",
              "       0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0,\n",
              "       0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0,\n",
              "       0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0,\n",
              "       0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0,\n",
              "       1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1,\n",
              "       1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1,\n",
              "       0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0,\n",
              "       0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0,\n",
              "       0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0,\n",
              "       0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0,\n",
              "       0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0,\n",
              "       1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1,\n",
              "       1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1,\n",
              "       0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0,\n",
              "       0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0,\n",
              "       0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0,\n",
              "       0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0,\n",
              "       0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0,\n",
              "       1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1,\n",
              "       1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1,\n",
              "       0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0,\n",
              "       0, 0, 0, 0, 1, 1, 0, 0, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0W7JKnzHrZzF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y1_train=y_c[:400]\n",
        "y1_test=y_c[400:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u4F6T__gq0C9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "94e9faf0-3e3d-4805-9782-3d205fdce424"
      },
      "source": [
        "print(y1_train.shape)\n",
        "print(y1_test.shape)\n"
      ],
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(400,)\n",
            "(269,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sNPlpyQQnwTy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.random.seed(1612)\n",
        "test = pd.DataFrame()\n",
        "model = Sequential()\n",
        "model.add(Dense(30, activation='relu', input_dim=dim))\n",
        "model.add(Dense(10, activation='relu'))\n",
        "model.add(Dense(3, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.fit(X_train, y1_train, validation_data=(X_test, y1_test), epochs=100, batch_size=20, verbose=2)\n",
        "test = model.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AntQNMTcsitc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "70909d26-55fe-4fac-b58e-9034c12ef791"
      },
      "source": [
        "acc_df = pd.DataFrame()\n",
        "acc_df['predict'] = test.flatten()\n",
        "acc_df.head()"
      ],
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>predict</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.000003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.000006</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.000003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.000002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.000083</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    predict\n",
              "0  0.000003\n",
              "1  0.000006\n",
              "2  0.000003\n",
              "3  0.000002\n",
              "4  0.000083"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 168
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wDUeCAD2tu3k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "outputId": "af84ef1d-bbea-462a-e464-30093d8b111f"
      },
      "source": [
        "acc_df['labels'] = y1_test\n",
        "acc_df.head(10)"
      ],
      "execution_count": 169,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>predict</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.000003</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.000006</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.000003</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.000002</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.000083</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.999998</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.999998</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.000007</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.000012</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.000949</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    predict  labels\n",
              "0  0.000003       0\n",
              "1  0.000006       0\n",
              "2  0.000003       0\n",
              "3  0.000002       0\n",
              "4  0.000083       0\n",
              "5  0.999998       1\n",
              "6  0.999998       1\n",
              "7  0.000007       0\n",
              "8  0.000012       0\n",
              "9  0.000949       0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 169
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HSOEezEQt88e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c1ccd6f7-0f37-480f-dbf9-9ad39d3b8789"
      },
      "source": [
        "1.0*sum((acc_df['labels']==1)==(acc_df['predict']>0.5))/len(acc_df['predict'])"
      ],
      "execution_count": 182,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9776951672862454"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 182
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VnmCUpqxkzhj",
        "colab_type": "text"
      },
      "source": [
        "## Task 2. Classify all days of the week\n",
        "Train a neural network against the origial categorical label. Use 5 layers of 40,15,5 and 7 (outputs, representing probabilities for a current input to correspond to each of the weekdays) neurons over the training sample, evaluating its performance over the test sample (use 'categorical_accurary'). Report the acheived accuracy (categorical) over the test sample.\n",
        "\n",
        "First three layers use relu activation function, last one - sigmoid.\n",
        "Use loss='binary_crossentropy', optimizer='adam', 200 epochs, batch_size=20"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gT4CTUAVkzhj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}